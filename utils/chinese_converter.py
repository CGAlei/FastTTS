"""
Robust Traditional to Simplified Chinese Converter
Provides multiple fallback layers to ensure conversion never fails
"""

import logging
from typing import List, Dict, Any, Optional

logger = logging.getLogger(__name__)

# Try to import OpenCC
try:
    from opencc import OpenCC
    OPENCC_AVAILABLE = True
except ImportError:
    OpenCC = None
    OPENCC_AVAILABLE = False


class ChineseConverter:
    """
    Robust Traditional to Simplified Chinese converter with multiple fallback layers
    
    Conversion Priority:
    1. OpenCC (tw2s) - Primary conversion method
    2. UI Compatibility Mapping - Manual overrides for OpenCC gaps
    3. Comprehensive Character Mapping - Emergency fallback
    
    Never fails - always returns some form of conversion
    """
    
    def __init__(self):
        self.cc = None
        self.conversion_stats = {
            'opencc_conversions': 0,
            'ui_mapping_conversions': 0,
            'manual_mapping_conversions': 0,
            'total_processed': 0
        }
        
        # Initialize OpenCC if available
        self._init_opencc()
        
        # UI compatibility mapping for edge cases OpenCC doesn't handle well
        self.ui_compatibility_mapping = {
            'ÈÇ£Âπ∫': 'ÈÇ£‰πà', 'ÈÇ£È∫Ω': 'ÈÇ£‰πà',
            'Ë¶ÅÂπ∫': 'Ë¶Å‰πà', 'Ë¶ÅÈ∫Ω': 'Ë¶Å‰πà', 
            '‰ªÄÂπ∫': '‰ªÄ‰πà', '‰ªÄÈ∫Ω': '‰ªÄ‰πà',
            'Áû≠': '‰∫Ü', 'È∫Ω': '‰πà', 'Âπ∫': '‰πà',
            'Êñº': '‰∫é', 'Áà≤': '‰∏∫', 'Ëàá': '‰∏é',
            'ÈÅé': 'Ëøá', '‰æÜ': 'Êù•', 'ÊôÇ': 'Êó∂',
            'ÂÄã': '‰∏™', 'ÂÄë': '‰ª¨', 'ÈÄô': 'Ëøô',
            'Á®Æ': 'Áßç', 'Êáâ': 'Â∫î', 'ÊúÉ': '‰ºö',
            'Ë™™': 'ËØ¥', 'ÈÇÑ': 'Ëøò', 'Ê≤í': 'Ê≤°',
            # Special case: OpenCC converts È°ØËëó‚ÜíÊòæËëó but standard is ÊòæÁùÄ
            'È°ØËëó': 'ÊòæÁùÄ', 'ËëóÂêç': 'ËëóÂêç'  # ËëóÂêç keeps Ëëó in Simplified
        }
        
        # Comprehensive Traditional‚ÜíSimplified character mapping (emergency fallback)
        self.manual_char_mapping = {
            # Basic frequent characters
            'Âúã': 'ÂõΩ', 'Â≠∏': 'Â≠¶', 'Êù±': '‰∏ú', 'Á∂ì': 'Áªè', 'Áôº': 'Âèë',
            'Èï∑': 'Èïø', 'Èñã': 'ÂºÄ', 'Èóú': 'ÂÖ≥', 'ÈñÄ': 'Èó®', 'Âïè': 'ÈóÆ',
            'Èñì': 'Èó¥', 'Ê•≠': '‰∏ö', 'Áî¢': '‰∫ß', 'Âãô': 'Âä°', 'Âì°': 'Âëò',
            'Èöõ': 'ÈôÖ', 'Èªû': 'ÁÇπ', 'Á∑ö': 'Á∫ø', 'Áæ©': '‰πâ', 'Ë≠∞': 'ËÆÆ',
            'Ë™ç': 'ËÆ§', 'Ë≠ò': 'ËØÜ', 'ÂØ¶': 'ÂÆû', 'Èöõ': 'ÈôÖ', 'Áèæ': 'Áé∞',
            'Ê©ü': 'Êú∫', 'Êßã': 'ÊûÑ', 'Ê∫ñ': 'ÂáÜ', 'Ê®ô': 'Ê†á', 'Á¢∫': 'Á°Æ',
            'Á∏Ω': 'ÊÄª', 'Áµ±': 'Áªü', 'Ê¢ù': 'Êù°', 'Âúò': 'Âõ¢', 'ÈÅî': 'Ëææ',
            'ÈÅã': 'Ëøê', 'ÈÄ≤': 'Ëøõ', 'ÈÅ∏': 'ÈÄâ', 'ÈÄ£': 'Ëøû', 'Â∞é': 'ÂØº',
            'Ââµ': 'Âàõ', 'Èüø': 'Âìç', 'ËÅ≤': 'Â£∞', 'È°å': 'È¢ò', 'È°û': 'Á±ª',
            'Ë≥™': 'Ë¥®', 'Á¥ö': 'Á∫ß', 'Ê•µ': 'ÊûÅ', 'Ê±∫': 'ÂÜ≥', 'Â±§': 'Â±Ç',
            'Áï∞': 'ÂºÇ', 'Ë≠∑': 'Êä§', 'Ë¶ñ': 'ËßÜ', 'Ë¶∫': 'Ëßâ', 'ËßÄ': 'ËßÇ',
            'ËÅΩ': 'Âê¨', 'ËÆÄ': 'ËØª', 'ÂØ´': 'ÂÜô', 'Ë™û': 'ËØ≠', 'Ë©±': 'ËØù',
            'Ë©û': 'ËØç', 'Ë≠Ø': 'ËØë', 'Ë®ò': 'ËÆ∞', 'ÈåÑ': 'ÂΩï', 'Â†±': 'Êä•',
            'Á¥ô': 'Á∫∏', 'Êõ∏': '‰π¶', 'Á≠Ü': 'Á¨î', 'Áï´': 'Áîª', 'Âúñ': 'Âõæ',
            'Â†¥': 'Âú∫', 'Ëôï': 'Â§Ñ', 'Ëæ¶': 'Âäû', 'Âãô': 'Âä°', 'Ë≤ª': 'Ë¥π',
            'ÂÉπ': '‰ª∑', 'Ë≤∑': '‰π∞', 'Ë≥£': 'Âçñ', 'Ë≤®': 'Ë¥ß', 'Ë≤°': 'Ë¥¢',
            'Èå¢': 'Èí±', 'ÈäÄ': 'Èì∂', 'Èêµ': 'ÈìÅ', 'Èãº': 'Èí¢', 'ÈäÖ': 'Èìú',
            'Ëªä': 'ËΩ¶', 'È£õ': 'È£û', 'Ëàπ': 'Ëàπ', 'Èõª': 'Áîµ', 'Á∂≤': 'ÁΩë',
            'Ë®à': 'ËÆ°', 'Ë®≠': 'ËÆæ', 'ÂÇô': 'Â§á', 'Âô®': 'Âô®', 'Ë°ì': 'ÊúØ',
            'ÈÜ´': 'Âåª', 'Ëó•': 'ËçØ', 'ÁôÇ': 'Áñó', 'ÁóÖ': 'ÁóÖ', 'Èô¢': 'Èô¢',
            'È§ä': 'ÂÖª', 'Ë≠∑': 'Êä§', 'Â∫∑': 'Â∫∑', 'ÂÅ•': 'ÂÅ•', 'Ê™¢': 'Ê£Ä',
            'Ê∏¨': 'Êµã', 'Ë©¶': 'ËØï', 'È©ó': 'È™å', 'Ê™¢': 'Ê£Ä', 'Êü•': 'Êü•',
            'Ë™ø': 'Ë∞É', 'ÁØÄ': 'ËäÇ', 'Âà∂': 'Âà∂', 'Êéß': 'Êéß', 'ÁÆ°': 'ÁÆ°',
            'ÁêÜ': 'ÁêÜ', 'Ë¶è': 'ËßÑ', 'ÁØÑ': 'ËåÉ', 'Ê∫ñ': 'ÂáÜ', 'Ââá': 'Âàô',
            'Âæã': 'Âæã', 'Ê≥ï': 'Ê≥ï', 'Ê¨ä': 'ÊùÉ', 'Âà©': 'Âà©', 'Áæ©': '‰πâ',
            
            # Missing characters found in tests - CRITICAL ADDITIONS
            'Êøü': 'Êµé', 'Áøí': '‰π†', 'Â∞ç': 'ÂØπ', 'Áµ°': 'Áªú', 'ÊúÉ': '‰ºö',
            'ÁÇ∫': '‰∏∫', 'ÈÄô': 'Ëøô', 'ÂÄã': '‰∏™', 'ÂÄë': '‰ª¨', '‰æÜ': 'Êù•',
            'ÊôÇ': 'Êó∂', 'Á®Æ': 'Áßç', 'Êáâ': 'Â∫î', 'Ë™™': 'ËØ¥', 'ÈÇÑ': 'Ëøò',
            'Ê≤í': 'Ê≤°', 'ÈÅé': 'Ëøá', 'Ëàá': '‰∏é', 'Êñº': '‰∫é', 'Áà≤': '‰∏∫',
            'ÂÑò': 'Â∞Ω', 'Áõ°': 'Â∞Ω', 'Âæû': '‰ªé', 'Ë°Ü': '‰ºó', 'Áúæ': '‰ºó',
            'È´î': '‰Ωì', 'ÊÖã': 'ÊÄÅ', 'ËÆä': 'Âèò', 'ÈÅ∑': 'ËøÅ', 'ËΩâ': 'ËΩ¨',
            'ÂÇ≥': '‰º†', 'Áµ±': 'Áªü', 'Êº¢': 'Ê±â', 'Áï∂': 'ÂΩì', 'Èª®': 'ÂÖö',
            
            # CRITICAL: Missing characters from real session data (20250802_234941)
            'ÂÖ©': '‰∏§', 'ÈÑ∞': 'ÈÇª', 'ÂÇ¢': 'ÂÆ∂', 'Èõñ': 'ËôΩ', 'ÁÑ∂': 'ÁÑ∂',
            'Âæå': 'Âêé', 'Âçª': 'Âç¥', 'Áµê': 'Áªì', 'ÊûÑ': 'ÊûÑ', 'Ëëó': 'ÁùÄ',
            'È°Ø': 'Êòæ', 'È∫º': '‰πà', 'È∫Ω': '‰πà', 'Âæå': 'Âêé', '‰æÜ': 'Êù•', 
            'Â§ß': 'Â§ß', 'ÂÇ¢': 'ÂÆ∂', 'È´î': '‰Ωì', 'Ë£Ω': 'Âà∂', 'ÂÖß': 'ÂÜÖ',
            'Âú®': 'Âú®', 'ÊÄß': 'ÊÄß', 'ÂàÜ': 'ÂàÜ', 'Ê∞¥': 'Ê∞¥', 'Â∂∫': 'Â≤≠',
            'Âóé': 'Âêó', 'Èñ§': 'Âêà', 'Ê≥ï': 'Ê≥ï', 'Âñ™': '‰∏ß', 'Â§±': 'Â§±',
            'È†ª': 'È¢ë', 'ÁπÅ': 'ÁπÅ', 'ÊπØ': 'Ê±§', 'Ê≠¶': 'Ê≠¶', 'Âπæ': 'Âá†',
            '‰πé': '‰πé', 'ÁµÇ': 'Áªà', 'Áîü': 'Áîü', 'Ë±°': 'Ë±°', 'Âæµ': 'ÂæÅ',
            'Ëºï': 'ËΩª', 'Êòì': 'Êòì', 'Ê∞∏': 'Ê∞∏', 'ÈÅ†': 'Ëøú', 'ËÆì': 'ËÆ©',
            'ÈÇ£': 'ÈÇ£', 'Ê®£': 'Ê†∑', 'ÈÄô': 'Ëøô', 'Ê®£': 'Ê†∑', 'Èõ£': 'Èöæ',
            'ÈÅì': 'ÈÅì', 'ÂàÜ': 'ÂàÜ', 'ÈÅì': 'ÈÅì', 'Êèö': 'Êâ¨', 'Èë£': 'Èï≥',
            # Additional critical mappings from session
            'Ëøë': 'Ëøë', 'Èõñ': 'ËôΩ', 'ÁÑ∂': 'ÁÑ∂', 'Êßã': 'ÊûÑ', 'È°Ø': 'Êòæ',
            'Ëëó': 'ÁùÄ', 'Áµê': 'Áªì', 'Êßã': 'ÊûÑ', 'È†ª': 'È¢ë', 'ÁπÅ': 'ÁπÅ',
            
            # Political and geographical
            'Ëá∫': 'Âè∞', 'ÁÅ£': 'Êπæ', 'Â≥∂': 'Â≤õ', 'ÁúÅ': 'ÁúÅ', 'Á∏£': 'Âéø',
            'ÂçÄ': 'Âå∫', 'ÈéÆ': 'Èïá', 'ÈÑâ': '‰π°', 'Êùë': 'Êùë', 'Ë°ó': 'Ë°ó',
            'Ëôü': 'Âè∑', 'Ê®ì': 'Ê•º', 'Â±§': 'Â±Ç', 'ÂÆ§': 'ÂÆ§', 'Êà∂': 'Êà∑',
            # Time and numbers
            'ÊôÇ': 'Êó∂', 'Èñì': 'Èó¥', 'Èêò': 'Èíü', 'ÂàÜ': 'ÂàÜ', 'Áßí': 'Áßí',
            'ÈÄ±': 'Âë®', 'Ê≠≤': 'Â≤Å', 'ÈΩ°': 'ÈæÑ', 'Ê≠∑': 'ÂéÜ', 'ÊõÜ': 'ÂéÜ',
            'ÂÑÑ': '‰∫ø', 'Ëê¨': '‰∏á', 'ÂçÉ': 'ÂçÉ', 'Áôæ': 'Áôæ', 'Êãæ': 'ÂçÅ',
            # Body and nature  
            'È†≠': 'Â§¥', 'Ëáâ': 'ËÑ∏', 'Áúº': 'Áúº', 'Èºª': 'Èºª', 'Âò¥': 'Âò¥',
            'ËÄ≥': 'ËÄ≥', 'Êâã': 'Êâã', 'ËÖ≥': 'ËÑö', 'ËÖø': 'ËÖø', 'Ë∫´': 'Ë∫´',
            'È´î': '‰Ωì', 'ÂøÉ': 'ÂøÉ', 'ËÖ¶': 'ËÑë', 'Ë°Ä': 'Ë°Ä', 'È™®': 'È™®',
            'Ê®π': 'Ê†ë', 'Ëä±': 'Ëä±', 'Ëçâ': 'Ëçâ', 'Ëëâ': 'Âè∂', 'Êûú': 'Êûú',
            'È≥•': 'È∏ü', 'È≠ö': 'È±º', 'Ëü≤': 'Ëô´', 'Áç∏': 'ÂÖΩ', 'Èæç': 'Èæô',
        }
    
    def _init_opencc(self):
        """Initialize OpenCC converter with error handling"""
        if not OPENCC_AVAILABLE:
            logger.warning("üö´ OpenCC not available - using fallback conversion only")
            return
            
        try:
            self.cc = OpenCC('tw2s')
            logger.info("‚úÖ OpenCC converter initialized (tw2s)")
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize OpenCC converter: {e}")
            self.cc = None
    
    def convert_word(self, word: str) -> str:
        """
        Convert a single word from Traditional to Simplified Chinese
        Uses multiple fallback methods to ensure conversion never fails
        """
        if not word:
            return word
            
        original_word = word
        self.conversion_stats['total_processed'] += 1
        
        # Method 1: UI compatibility mapping (highest priority for known edge cases)
        if word in self.ui_compatibility_mapping:
            converted = self.ui_compatibility_mapping[word]
            self.conversion_stats['ui_mapping_conversions'] += 1
            logger.debug(f"‚úÖ UI mapping: '{original_word}' ‚Üí '{converted}'")
            return converted
        
        # Method 2: OpenCC conversion (if available)
        if self.cc:
            try:
                converted = self.cc.convert(word)
                if converted != original_word:
                    self.conversion_stats['opencc_conversions'] += 1
                    logger.debug(f"‚úÖ OpenCC: '{original_word}' ‚Üí '{converted}'")
                    return converted
            except Exception as e:
                logger.warning(f"‚ùå OpenCC conversion failed for '{word}': {e}")
        
        # Method 3: Character-by-character manual mapping (emergency fallback)
        converted_chars = []
        conversion_made = False
        unconverted_traditional = []
        
        for char in word:
            if char in self.manual_char_mapping:
                converted_chars.append(self.manual_char_mapping[char])
                conversion_made = True
                logger.debug(f"‚úÖ Manual char: '{char}' ‚Üí '{self.manual_char_mapping[char]}'")
            else:
                converted_chars.append(char)
                # Check if this is a Traditional character we're missing
                if '\u4e00' <= char <= '\u9fff':  # Chinese character range
                    # Common Traditional characters we should catch
                    known_traditional = set(self.manual_char_mapping.keys()) | set(self.ui_compatibility_mapping.keys())
                    if char not in known_traditional:
                        # Check if it looks Traditional by testing some patterns
                        traditional_indicators = ['Èæç', 'Âúã', 'Â≠∏', 'ÈÅé', '‰æÜ', 'ÊôÇ', 'ÂÄã', 'ÂÄë', 'ÈÄô', 'Â∞ç', 'ÊúÉ', 'Ë™™', 'ÈÇÑ', 'Ê≤í', 'Âæå', 'Èï∑', 'Èñã', 'Èóú', 'ÈñÄ', 'Âïè', 'Èñì', 'Ê•≠', 'Áî¢', 'Âãô', 'Âì°', 'Èöõ', 'Èªû', 'Á∑ö', 'Áæ©', 'Ë≠∞', 'Ë™ç', 'Ë≠ò', 'ÂØ¶', 'Áèæ', 'Ê©ü', 'Êßã', 'Ê∫ñ', 'Ê®ô', 'Á¢∫', 'Á∏Ω', 'Áµ±', 'Ê¢ù', 'Âúò', 'ÈÅî', 'ÈÅã', 'ÈÄ≤', 'ÈÅ∏', 'ÈÄ£', 'Â∞é', 'Ââµ', 'Èüø', 'ËÅ≤', 'È°å', 'È°û', 'Ë≥™', 'Á¥ö', 'Ê•µ', 'Ê±∫', 'Â±§', 'Áï∞', 'Ë≠∑', 'Ë¶ñ', 'Ë¶∫', 'ËßÄ', 'ËÅΩ', 'ËÆÄ', 'ÂØ´', 'Ë™û', 'Ë©±', 'Ë©û', 'Ë≠Ø', 'Ë®ò', 'ÈåÑ', 'Â†±', 'Á¥ô', 'Êõ∏', 'Á≠Ü', 'Áï´', 'Âúñ', 'Â†¥', 'Ëôï', 'Ëæ¶', 'Ë≤ª', 'ÂÉπ', 'Ë≤∑', 'Ë≥£', 'Ë≤®', 'Ë≤°', 'Èå¢', 'ÈäÄ', 'Èêµ', 'Èãº', 'ÈäÖ', 'Ëªä', 'È£õ', 'Èõª', 'Á∂≤', 'Ë®à', 'Ë®≠', 'ÂÇô', 'Ë°ì', 'ÈÜ´', 'Ëó•', 'ÁôÇ', 'Ê™¢', 'Ê∏¨', 'Ë©¶', 'È©ó', 'Êü•', 'Ë™ø', 'ÁØÄ', 'Êéß', 'ÁÆ°', 'Ë¶è', 'ÁØÑ', 'Ââá', 'Ê¨ä', 'Êøü', 'Áøí', 'Áµ°', 'ÁÇ∫', 'Á®Æ', 'Êáâ', 'Ëàá', 'Êñº', 'ÂÑò', 'Áõ°', 'Âæû', 'Ë°Ü', 'Áúæ', 'È´î', 'ÊÖã', 'ËÆä', 'ÈÅ∑', 'ËΩâ', 'ÂÇ≥', 'Êº¢', 'Áï∂', 'Èª®', 'Ëá∫', 'ÁÅ£', 'Â≥∂', 'Á∏£', 'ÂçÄ', 'ÈéÆ', 'ÈÑâ', 'Ëôü', 'Ê®ì', 'Êà∂', 'Èêò', 'ÈÄ±', 'Ê≠≤', 'ÈΩ°', 'Ê≠∑', 'ÊõÜ', 'ÂÑÑ', 'Ëê¨', 'Êãæ', 'È†≠', 'Ëáâ', 'ËÖ≥', 'ËÖ¶', 'Ê®π', 'Ëëâ', 'È≥•', 'È≠ö', 'Ëü≤', 'Áç∏', 'ÂÖ©', 'ÈÑ∞', 'ÂÇ¢', 'Èõñ', 'ÁÑ∂', 'Âçª', 'Áµê', 'Ëëó', 'È°Ø', 'È∫º', 'È∫Ω', 'ÂÖß', 'Â∂∫', 'Âóé', 'Èñ§', 'Âñ™', 'È†ª', 'ÁπÅ', 'ÊπØ', 'Âπæ', 'ÁµÇ', 'Ë±°', 'Âæµ', 'Ëºï', 'Ê∞∏', 'ÈÅ†', 'ËÆì', 'Ê®£', 'Èõ£', 'Êèö', 'Èë£', 'Êßã', 'Ëøë']
                        # This is a very rough heuristic but helps identify missed Traditional chars
                        unconverted_traditional.append(char)
        
        if conversion_made:
            converted = ''.join(converted_chars)
            self.conversion_stats['manual_mapping_conversions'] += 1
            logger.debug(f"‚úÖ Manual mapping: '{original_word}' ‚Üí '{converted}'")
            
            # Log any unconverted Traditional characters for future mapping
            if unconverted_traditional:
                logger.warning(f"‚ö†Ô∏è POTENTIAL TRADITIONAL CHARS NOT CONVERTED in '{original_word}': {unconverted_traditional}")
            
            return converted
        
        # Check if entire word contains potential Traditional characters
        potential_traditional = []
        for char in word:
            if '\u4e00' <= char <= '\u9fff':  # Chinese character
                known_chars = set(self.manual_char_mapping.values()) | {'ÁöÑ', '‰∫Ü', 'Âú®', 'ÊòØ', 'Êàë', 'Êúâ', 'Âíå', '‰∫∫', 'Ëøô', '‰∏≠', 'Â§ß', '‰∏∫', '‰∏ä', '‰∏™', 'ÂõΩ', 'Êàë', '‰ª•', 'Ë¶Å', '‰ªñ', 'Êó∂', 'Êù•', 'Áî®', '‰ª¨', 'Áîü', 'Âà∞', '‰Ωú', 'Âú∞', '‰∫é', 'Âá∫', 'Â∞±', 'ÂàÜ', 'ÂØπ', 'Êàê', '‰ºö', 'ÂèØ', '‰∏ª', 'Âèë', 'Âπ¥', 'Âä®', 'Âêå', 'Â∑•', '‰πü', 'ËÉΩ', '‰∏ã', 'Ëøá', 'Â≠ê', 'ËØ¥', '‰∫ß', 'Áßç', 'Èù¢', 'ËÄå', 'Êñπ', 'Âêé', 'Â§ö', 'ÂÆö', 'Ë°å', 'Â≠¶', 'Ê≥ï', 'ÊâÄ', 'Ê∞ë', 'Âæó', 'Áªè', 'ÂçÅ', '‰∏â', '‰πã', 'Ëøõ', 'ÁùÄ', 'Á≠â', 'ÈÉ®', 'Â∫¶', 'ÂÆ∂', 'Áîµ', 'Âäõ', 'Èáå', 'Â¶Ç', 'Ê∞¥', 'Âåñ', 'È´ò', 'Ëá™', '‰∫å', 'ÁêÜ', 'Ëµ∑', 'Â∞è', 'Áâ©', 'Áé∞', 'ÂÆû', 'Âä†', 'Èáè', 'ÈÉΩ', '‰∏§', '‰Ωì', 'Âà∂', 'Êú∫', 'ÂΩì', '‰Ωø', 'ÁÇπ', '‰ªé', '‰∏ö', 'Êú¨', 'Âéª', 'Êää', 'ÊÄß', 'Â•Ω', 'Â∫î', 'ÂºÄ', 'ÂÆÉ', 'Âêà', 'Ëøò', 'Âõ†', 'Áî±', 'ÂÖ∂', '‰∫õ', 'ÁÑ∂', 'Ââç', 'Â§ñ', 'Â§©', 'Êîø', 'Âõõ', 'Êó•', 'ÈÇ£', 'Á§æ', '‰πâ', '‰∫ã', 'Âπ≥', 'ÂΩ¢', 'Áõ∏', 'ÂÖ®', 'Ë°®', 'Èó¥', 'Ê†∑', '‰∏é', 'ÂÖ≥', 'ÂêÑ', 'Èáç', 'Êñ∞', 'Á∫ø', 'ÂÜÖ', 'Êï∞', 'Ê≠£', 'ÂøÉ', 'Âèç', '‰Ω†', 'Êòé', 'Áúã', 'Âéü', 'Âèà', '‰πà', 'Âà©', 'ÊØî', 'Êàñ', '‰ΩÜ', 'Ë¥®', 'Ê∞î', 'Á¨¨', 'Âêë', 'ÈÅì', 'ÂëΩ', 'Ê≠§', 'Âèò', 'Êù°', 'Âè™', 'Ê≤°', 'Áªì', 'Ëß£', 'ÈóÆ', 'ÊÑè', 'Âª∫', 'Êúà', 'ÂÖ¨', 'Êó†', 'Á≥ª', 'ÂÜõ', 'Âæà', 'ÊÉÖ', 'ËÄÖ', 'ÊúÄ', 'Á´ã', '‰ª£', 'ÊÉ≥', 'Â∑≤', 'ÈÄö', 'Âπ∂', 'Êèê', 'Áõ¥', 'È¢ò', 'ÂÖö', 'Á®ã', 'Â±ï', '‰∫î', 'Êûú', 'Êñô', 'Ë±°', 'Âëò', 'Èù©', '‰Ωç', 'ÂÖ•', 
                                'Áªß', 'ÊÄª', 'Âç≥', 'ËΩ¶', 'Èáç', '‰æø', 'Êñó', 'ÁôΩ', 'Ë∞É', 'Êª°', 'Âéø', 'Â±Ä', 'ÁÖß', 'ÂèÇ', 'Á∫¢', 'ÁªÜ', 'Âºï', 'Âê¨', 'ËØ•', 'ÈìÅ', '‰ª∑', '‰∏•', 'Èæô', 'Âúü', 'Âø´', 'Ëøá', 'Èùû', 'ËΩ¨', '‰ªä', 'ËØÜ', 'Âπ≤', 'Âäû', 'Ê†á', 'ÊçÆ', 'Ê±Ç', 'Áªü', 'Ê¨°', 'Â§Ñ', 'Âõ¢', 'ÂÜ≥', 'ÂìÅ', 'Â£∞', '‰∫â', 'ÊÄù', 'ÂÖ´', 'ÂÆå', 'Ëà¨', 'Âèó', 'ËÆ°', 'Èô§', 'Âç¥', 'ÁªÑ', 'Âè∑', 'Âàó', 'Ê∏©', '‰ªÄ', 'ÂøÖ', 'Èô¢', 'Êòì', 'Êó©', 'ËÆ∫', 'ÂêÉ', 'ÂÜç', '‰ªª', 'Êéå', 'Á≤æ', '‰πù', '‰Ω†', 'ÂÅö', 'ÊØè', 'ÈõÜ', 'Âçä', 'Á°Æ', 'ÂÄô', 'ÈôÖ', 'ÂçÉ', 'Êåá', 'Ê∑±', 'Êùé', 'Êï¥', 'Ëµ∞', 'Á©∂', 'ËßÇ', 'Âèñ', 'ËäÇ', 'ÂéÜ', 'Áß∞', 'Âçï', 'È©¨', 'Èöæ', '‰ª∑', 'Â•ã', 'ËÆ∏', 'Âø´', 'Âüé', 'Âõû', 'ÈÄâ', 'ÂåÖ', 'Âõ¥', '‰∏ì', 'Êõ¥', 'Âáª', 'Â§ç', 'ÂÖ≠', 'Â∞ë', 'Âçé', 'Èò∂', 'Ê∏Ö', 'È£é', 'Êãâ', '‰Ωè', 'ÂÜô', 'ÂÜú', 'ÂÖ´', 'Âûã', 'Áü≥', 'Êé•', 'Ëøë', 'Â§á', 'Ë¥π', '‰∏ñ', 'Èó®', 'Áâπ', 'Âàô', 'Â∏∏', 'È¢Ü', '‰∫î', 'Â§á', 'Ë£Ö', 'Êä•', 'ÊØõ', 'Á©∂', 'ÁÆó', 'Âë®', 'Áª¥', 'Êñ≠', 'ÊûÅ', 'ÁÆ°', 'Ëøê', '‰ª∂', 'Áéá', '‰øù', 'ÂÖà', 'ÊÅØ', 'Â∏å', 'ÊÄÅ', 'Ê≠•', 'Á¶ª', 'Êµã', 'ËØï', 'ÊÆµ', 'Êåâ', 'ËØ≠', 'Âø´', 'Èô§', 'Âë®', 'ÂÆπ', 'ÂÖ±', 'ÂÖµ', '‰Ωç', 'Âà´', 'Â§ü', 'ÂïÜ', '‰ºº', 'Èò≥', 'Âå∫', '‰∏É', 'È£ü', 'Ëøû', 'ËØ∑', 'Êµ∑', 'Âº∫', 'Áªô', '‰Ωï', 'Ëâ≤', 'Èïø', 'Ë∑Ø', 'Âç≥', 'Áªá', 'Êãø', '‰∫§', 'Ê∂à', 'ÂÖã', '‰∏î', '‰Ωè', 'Áßë', 'ËÆ≠', 'ÁÅ´', 'Ëæπ', 'ÂÖâ', 'È™å', 'Êî∂', 'ËÆ∞', '‰Ωè', '‰π¶', 'Êàø', '‰ªª', 'Áéã', 'Â≠ò', 'Â§™', 'Êñá', 'Âèã', 'Ëã•', 'Áßç', 'Â≠ò', 'Ëä±', 'Ë∞à', '‰∏á', 'Âà∂', 'Á°Æ', '‰º†', 'Âä†', 'ÂÆâ', 'ÈÖç', 'Á©∫', 'Á∫ß', 'Â∏É', 'Áªà', 'Ëµ∞', 'Èöè', 'Âë¢', '‰π†', 'Â§ú', 'ÂÖ∑', 'Êåâ', 'Â¢û', 'Âü∫', 'ÊµÅ', 'Ê∂à', 'ÂÜµ', 'Á≠î', 'Ê≤ª', 'Áî∑', 'ÊãÖ', 'ÂçÉ', 'ÊúØ', 'Á∫∏', '‰Ωô', 'Áæ§', 'ÂæÄ', 'È°∫', 'È¶ñ', 'ÊïÖ', 'Âè§', 'Èó®', 'Âõæ', 'Âñú', 'Â•≥', 'Êùê', 'ËßÜ', 'Âøó', 'Âùö', '‰æõ', 'ËåÉ', 'Ëã¶', '‰ºç', 'ÊùÄ', 'Ê≠¢', 'ÁªÉ', 'Êïå', 'Èù†', 'ÁÆó', 'Áõæ', 'Âìç', '‰∫ë', 'Â∑Æ', 'Áôæ', 'Êú®', '‰ºó', 'Êùø', 'Âè≥', 'Â¶á', 'Â∑¶', 'Â§¥', 'Â∞î', 'Âàõ', 'Áâõ', 'Ëø∞', 'Ëã•', 'Ë∞Å', 'Êò•', 'ÂÖª', 'ÊÅØ', '‰π°', 'Â∏å', 'ÂΩ±', 'Â≤Å', 'Êàø', 'ÈÄ†', 'Ëææ', 'Ê°à', 'ÂΩï', 'Ê¥æ', 'ÁóÖ', 'Ë£Ö', 'Èôê', 'Âçó', 'ÁÉ≠', 'Ê±ü', 'Âàá', 'Êäï', 'Ê†º', 'Â§±', '‰∫¨', 'Áâá', 'Ëßí', 'Áº∫', 'Èí±', 'ÊäÄ', 'Ë∂ä', 'Ëøú', 'Ê¥ã', 'Ê≥¢', 'ÈªÑ', 'ÂÖ∏', 'Ê¨¢', 'Â∏à', 'Â∫ï', 'Á∫™', 'Ê≥®', 'ËØæ', 'Èïá', 'Èò≤', 'Âúü', 'ÂØå', 'ÂéÇ', 'ÊîØ', 'Â¶à', 'Ë¥ü', 'Áî∞', 'Áã¨', 'Â∫è', '‰∫ö', 'ÂΩï', '‰π∞', 'Âëä', 'ÁªÜ', 'ÂÖ≠', 'Ë°Ä', 'Ë•ø', 'ÂÆà', 'Êé®', 'ËÅå', '‰∫≤', 'Ê∞∏', 'Ââ©', 'Âàù', 'Ê†°', 'Ê†ë', 'ÁÆÄ', 'ÂçÉ', 'Ê†°', 'ËµÑ', 'ÂÄí', 'È™å', 'Êúç', 'Êé®', 'Ê¥ª', 'Â§è', 'Êä§', 'Áâô', '‰π∞', 'È°π', 'ÂæÖ', 'ÂÆ¢', 'Êà∑', 'Á¶è', 'Â≤õ', 'Êú®', 'È¢Ñ', 'Èôç', 'Êùø', '‰∏É', 'ÊñØ', 'Êàø', 'Ê∏Ø', 'ËâØ', 'ËêΩ', '‰æã', 'ÂÅú', 'Êò•', 'Èò∂', 'Ê≤π', 'ÂáÜ', 'Áïô', 'ËÆ≤', 'Ê≠ª', 'Ë¥π', '‰∏¥', 'Âºü', 'Á§∫', 'Â±Ç', 'Êâß', 'Êùé', 'ÂÖª', '‰πî', 'Áºñ', 'Âç´', 'Ë¥•', 'Âä©', 'Á∫¶', 'ÊãÖ', 'Âùê', 'Ëçâ', 'ËÅö', 'ÁΩó', '‰∫ø', 'Âçà', 'Êãø', 'Âà§', '‰º§', 'Â∞æ', 'ËæÉ', 'ÁΩë', '‰Ωé', 'ÊÑà', 'ÊÑø', 'ÂÆù', 'Â±Ç', 'Âº±', 'Ê¥≤', 'Ëµ∂', 'Â±Ö', 'Ëàπ', 'Âèå', 'È£û', 'ÁßØ', 'ÂëÄ', 'Âùó', 'È°æ', 'Êó©', 'Áè≠', 'Êöñ', 'ÊôØ', 'ËôΩ', 'ÁöÆ', 'Â≠£', 'Èòø', 'Ë∞∑', 'Á∫∑', 'Èªò', 'Èí¢', 'Áßª', 'ÁØá', 'Áîª', 'ËØâ', 'Èõ®', '‰ªç', 'Á±≥', 'Â§´', 'Êùø', 'ÊùÄ', 'Ë¥•', '‰π±', 'Êâ´', 'Êå•', 'ÂÖç', 'Á¥ß', 'Áïô', 'Âª∫', 'ÊØÅ', 'Áõñ', 'Â≤∏', 'Èªë', 'ÁäØ', 'ÂæÆ', 'È≤ú', 'Èáá', '‰∫Æ', 'ÂóØ', 'Âá°', 'ËåÉ', 'ÂÆÅ', '‰ªÅ', 'Âç°', 'Ëé∑', 'Áâà', 'Êäó', 'Á°¨', '‰ªç', 'Êâø', 'Âè¶', 'Âë¢', 'Á°¨', 'ÁΩ™', 'Êõπ', 'Ëãè', 'Êùë', 'Ë¥µ', 'Êìç', 'Áõë', 'Ê¥ã', 'ËÉú', 'Âõ∫', 'Áà∂', 'Âè•', 'ÈÄè'}
                
                # If it's not in common simplified characters, it might be traditional
                if char not in known_chars and char not in self.manual_char_mapping and char not in self.ui_compatibility_mapping:
                    potential_traditional.append(char)
        
        if potential_traditional:
            logger.warning(f"üö® UNCONVERTED POTENTIAL TRADITIONAL CHARACTERS in '{original_word}': {potential_traditional}")
            logger.warning(f"   Add these to manual_char_mapping: {dict(zip(potential_traditional, ['?' for _ in potential_traditional]))}")
        
        # No conversion needed or possible - return original
        return original_word
    
    def convert_word_timings(self, word_timings: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Convert word timings from Traditional to Simplified Chinese
        NEVER fails - always returns converted or original data
        """
        if not word_timings:
            return word_timings
        
        converted_timings = []
        conversions_made = 0
        
        for timing in word_timings:
            original_word = timing.get("word", "")
            if not original_word:
                converted_timings.append(timing)
                continue
            
            converted_word = self.convert_word(original_word)
            
            # Create new timing object with converted word
            new_timing = timing.copy()
            new_timing["word"] = converted_word
            converted_timings.append(new_timing)
            
            if converted_word != original_word:
                conversions_made += 1
        
        # Log conversion summary
        if conversions_made > 0:
            logger.info(f"üîÑ Traditional‚ÜíSimplified conversion: {conversions_made}/{len(word_timings)} words converted")
            self._log_conversion_stats()
        else:
            logger.debug(f"‚úÖ No Traditional characters detected in {len(word_timings)} words")
        
        return converted_timings
    
    def convert_text(self, text: str) -> str:
        """
        Convert entire text from Traditional to Simplified Chinese
        """
        if not text:
            return text
            
        # Use OpenCC for full text conversion if available
        if self.cc:
            try:
                converted = self.cc.convert(text)
                if converted != text:
                    logger.info(f"üìù Text converted: {len(text)} chars ‚Üí {len(converted)} chars")
                return converted
            except Exception as e:
                logger.warning(f"OpenCC text conversion failed: {e}")
        
        # Fallback: character-by-character conversion
        converted_chars = []
        for char in text:
            if char in self.manual_char_mapping:
                converted_chars.append(self.manual_char_mapping[char])
            elif char in self.ui_compatibility_mapping:
                converted_chars.append(self.ui_compatibility_mapping[char])
            else:
                converted_chars.append(char)
        
        return ''.join(converted_chars)
    
    def _log_conversion_stats(self):
        """Log detailed conversion statistics"""
        stats = self.conversion_stats
        total_conversions = (stats['opencc_conversions'] + 
                           stats['ui_mapping_conversions'] + 
                           stats['manual_mapping_conversions'])
        
        if total_conversions > 0:
            details = []
            if stats['opencc_conversions'] > 0:
                details.append(f"{stats['opencc_conversions']} OpenCC")
            if stats['ui_mapping_conversions'] > 0:
                details.append(f"{stats['ui_mapping_conversions']} UI-mapping")
            if stats['manual_mapping_conversions'] > 0:
                details.append(f"{stats['manual_mapping_conversions']} manual")
            
            logger.info(f"üìä Conversion breakdown: {', '.join(details)}")
    
    def is_opencc_available(self) -> bool:
        """Check if OpenCC is available and working"""
        return self.cc is not None
    
    def get_conversion_stats(self) -> Dict[str, int]:
        """Get conversion statistics"""
        return self.conversion_stats.copy()
    
    def reset_stats(self):
        """Reset conversion statistics"""
        self.conversion_stats = {
            'opencc_conversions': 0,
            'ui_mapping_conversions': 0,
            'manual_mapping_conversions': 0,
            'total_processed': 0
        }
    
    def validate_simplified_chinese(self, word_timings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Validate that all words in word_timings are in Simplified Chinese
        
        Returns:
            Dict with validation results and any Traditional characters found
        """
        traditional_chars_found = set()
        traditional_words = []
        
        # Only flag characters that are EXCLUSIVELY Traditional (not used in Simplified)
        # These are characters that should NEVER appear in Simplified Chinese text
        exclusively_traditional_chars = {
            'Âúã', 'Â≠∏', 'Êù±', 'Á∂ì', 'Áôº', 'Èï∑', 'Èñã', 'Èóú', 'ÈñÄ', 'Âïè', 'Èñì', 'Ê•≠', 'Áî¢', 'Âãô', 'Âì°',
            'Èöõ', 'Èªû', 'Á∑ö', 'Áæ©', 'Ë≠∞', 'Ë™ç', 'Ë≠ò', 'ÂØ¶', 'Áèæ', 'Ê©ü', 'Êßã', 'Ê∫ñ', 'Ê®ô', 'Á¢∫',
            'Á∏Ω', 'Áµ±', 'Ê¢ù', 'Âúò', 'ÈÅî', 'ÈÅã', 'ÈÄ≤', 'ÈÅ∏', 'ÈÄ£', 'Â∞é', 'Ââµ', 'Èüø', 'ËÅ≤', 'È°å',
            'È°û', 'Ë≥™', 'Á¥ö', 'Ê•µ', 'Ê±∫', 'Â±§', 'Áï∞', 'Ë≠∑', 'Ë¶ñ', 'Ë¶∫', 'ËßÄ', 'ËÅΩ', 'ËÆÄ', 'ÂØ´',
            'Ë™û', 'Ë©±', 'Ë©û', 'Ë≠Ø', 'Ë®ò', 'ÈåÑ', 'Â†±', 'Á¥ô', 'Êõ∏', 'Á≠Ü', 'Áï´', 'Âúñ', 'Â†¥', 'Ëôï',
            'Ëæ¶', 'Ë≤ª', 'ÂÉπ', 'Ë≤∑', 'Ë≥£', 'Ë≤®', 'Ë≤°', 'Èå¢', 'ÈäÄ', 'Èêµ', 'Èãº', 'ÈäÖ', 'Ëªä', 'È£õ',
            'Èõª', 'Á∂≤', 'Ë®à', 'Ë®≠', 'ÂÇô', 'Ë°ì', 'ÈÜ´', 'Ëó•', 'ÁôÇ', 'Ê™¢', 'Ê∏¨', 'Ë©¶', 'È©ó', 'Êü•',
            'Ë™ø', 'ÁØÄ', 'Êéß', 'ÁÆ°', 'Ë¶è', 'ÁØÑ', 'Ââá', 'Ê¨ä', 'Êøü', 'Áøí', 'Áµ°', 'ÁÇ∫', 'Á®Æ', 'Êáâ',
            'Ëàá', 'Êñº', 'ÂÑò', 'Áõ°', 'Âæû', 'Ë°Ü', 'Áúæ', 'È´î', 'ÊÖã', 'ËÆä', 'ÈÅ∑', 'ËΩâ', 'ÂÇ≥', 'Êº¢',
            'Áï∂', 'Èª®', 'Ëá∫', 'ÁÅ£', 'Â≥∂', 'Á∏£', 'ÂçÄ', 'ÈéÆ', 'ÈÑâ', 'Ëôü', 'Ê®ì', 'Êà∂', 'Èêò', 'ÈÄ±',
            'Ê≠≤', 'ÈΩ°', 'Ê≠∑', 'ÊõÜ', 'ÂÑÑ', 'Ëê¨', 'Êãæ', 'È†≠', 'Ëáâ', 'ËÖ≥', 'ËÖ¶', 'Ê®π', 'Ëëâ', 'È≥•',
            'È≠ö', 'Ëü≤', 'Áç∏', 'ÂÖ©', 'ÈÑ∞', 'ÂÇ¢', 'Èõñ', 'Âæå', 'Âçª', 'Áµê', 'È°Ø', 'È∫º', 'È∫Ω',
            'ÂÖß', 'Â∂∫', 'Âóé', 'Èñ§', 'Âñ™', 'È†ª', 'ÁπÅ', 'ÊπØ', 'Âπæ', 'ÁµÇ', 'Ë±°', 'Âæµ', 'Ëºï', 'Ê∞∏',
            'ÈÅ†', 'ËÆì', 'Ê®£', 'Èõ£', 'Êèö', 'Èë£', 'Ë£Ω', 'ÈΩ£'
            # Note: Removed 'Ëëó' as it has valid uses in Simplified Chinese (ËëóÂêç, Ëëó‰Ωú, etc.)
        }
        
        for timing in word_timings:
            word = timing.get("word", "")
            word_has_traditional = False
            traditional_chars_in_word = []
            
            for char in word:
                if char in exclusively_traditional_chars:
                    traditional_chars_found.add(char)
                    traditional_chars_in_word.append(char)
                    word_has_traditional = True
            
            if word_has_traditional:
                traditional_words.append({
                    'word': word,
                    'traditional_chars': traditional_chars_in_word,
                    'timestamp': timing.get('timestamp', 0)
                })
        
        validation_result = {
            'is_valid': len(traditional_chars_found) == 0,
            'traditional_chars_found': list(traditional_chars_found),
            'traditional_words': traditional_words,
            'total_words_checked': len(word_timings)
        }
        
        if not validation_result['is_valid']:
            logger.warning(f"üö® TRUE Traditional characters detected in final output: {traditional_chars_found}")
            logger.warning(f"üîç Affected words: {[w['word'] for w in traditional_words]}")
        else:
            logger.info(f"‚úÖ Validation passed: All {len(word_timings)} words are properly Simplified Chinese")
        
        return validation_result


# Global instance
_chinese_converter = None

def get_chinese_converter() -> ChineseConverter:
    """Get the global Chinese converter instance"""
    global _chinese_converter
    if _chinese_converter is None:
        _chinese_converter = ChineseConverter()
    return _chinese_converter